{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC, LinearSVC # SVCは非線形SVM（Support Vector Classifier）\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# ファイル入出力ライブラリ\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML():\n",
    "    def __init__(self, categorical_columns, eval_kind):\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.eval_kind = eval_kind\n",
    "\n",
    "        # 2値分類ができるモデルをパイプラインで作成\n",
    "        self.pipelines = {\n",
    "#             'knn':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',KNeighborsClassifier())]),\n",
    "            'logistic':\n",
    "                Pipeline([('scl',StandardScaler()), ('est',LogisticRegression(random_state=1, class_weight=\"balanced\"))]),\n",
    "#             'rsvc':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',SVC(C=1.0,kernel='rbf',class_weight='balanced',random_state=1, probability=True))]),\n",
    "#             'lsvc':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',LinearSVC(C=1.0,class_weight='balanced',random_state=1))]),\n",
    "#             'rf':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',RandomForestClassifier(random_state=1))]),\n",
    "#             'gb':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',GradientBoostingClassifier(random_state=1))]),\n",
    "#             'mlp':\n",
    "#                 Pipeline([('scl',StandardScaler()), ('est',MLPClassifier(hidden_layer_sizes=(5,3), max_iter=500, random_state=1))])\n",
    "        }\n",
    "        \n",
    "    def read_data_file(self, file_path):\n",
    "        # objectで読み込むのがポイント！ 'Dependents_2'が'Dependents_2.0'となることを避けられる\n",
    "        dtype = {column: object for column in self.categorical_columns}\n",
    "        df = pd.read_csv(file_path, header=0, dtype=dtype)\n",
    "\n",
    "        X  = df.iloc[:,2:]            # 3列目以降を特徴量\n",
    "        ID = df.iloc[:,[0]]             # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "        y  = df.iloc[:,1]              # 2列目をクラス変数\n",
    "        \n",
    "        self.ID_name = ID.columns[0]\n",
    "        self.y_name = y.name\n",
    "        \n",
    "        return X, y, ID\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # データ前処理\n",
    "        X_pre = self.__preprocess_X(X)\n",
    "        y_pre = self.__preprocess_y(y)\n",
    "        \n",
    "        # one-hotエンコーディングヘッダをテストデータにも適用するため保持\n",
    "        self.X_columns = X_pre.columns.values\n",
    "#         \n",
    "#         # デバッグ文\n",
    "#         print('---X_columns start------------')\n",
    "#         display(self.X_columns)\n",
    "#         print('---X_columns end------------')\n",
    "        \n",
    "        # 全てのモデルでfitを行う（cross-validationで検証する）\n",
    "        # fit & evaluation\n",
    "        scores = {}\n",
    "        for pipe_name, pipeline in self.pipelines.items():\n",
    "            pipeline.fit(X_pre, y_pre)\n",
    "            cv_results = cross_val_score(pipeline,\n",
    "                             X_pre,\n",
    "                             y_pre.values,\n",
    "                             cv=3,\n",
    "                             scoring=self.eval_kind)\n",
    "\n",
    "            # cross-validationの平均値-標準偏差をスコアとする\n",
    "            scores[pipe_name] = cv_results.mean() - cv_results.std()\n",
    "            sorted_scores = self.__sort_dictionary(scores)\n",
    "\n",
    "        # アルゴリズムランキングと性能指標評価を出力\n",
    "        display(pd.Series(sorted_scores))\n",
    "\n",
    "        # eval_kindを用いて評価する\n",
    "        # 一番評価の良かったモデルを取っておく\n",
    "        best_algorithm = [*sorted_scores][0]\n",
    "#         print('best:{}'.format(best_algorithm))\n",
    "        self.best_model = self.pipelines[best_algorithm]\n",
    "    \n",
    "    # X前処理\n",
    "    def __preprocess_X(self, X):\n",
    "        # Xのone-hotエンコーディング\n",
    "        X_ohe = pd.get_dummies(X, dummy_na=True, columns=self.categorical_columns)\n",
    "\n",
    "        # 欠損値を平均で置き換える\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "        imp.fit(X_ohe)\n",
    "        X_ohe_columns = X_ohe.columns.values\n",
    "        X_ohe = pd.DataFrame(imp.transform(X_ohe), columns=X_ohe_columns)\n",
    "        \n",
    "        # デバッグ文\n",
    "        print('preprocess result-----')\n",
    "        display(X_ohe)\n",
    "        print('----------------------')\n",
    "        \n",
    "        return X_ohe\n",
    "\n",
    "    # y前処理\n",
    "    def __preprocess_y(self, y):\n",
    "        # yは欠損値を最頻値で置き換える\n",
    "        y_pre = y.fillna(y.mode()[0])\n",
    "#         # デバッグ文\n",
    "#         print('preprocess result-----')\n",
    "#         display(y_pre)\n",
    "#         print('----------------------')\n",
    "        return y_pre\n",
    "    \n",
    "    def __sort_dictionary(self, dict):\n",
    "        sorted_dict = {}\n",
    "        for k, v in sorted(dict.items(), key=lambda x: -x[1]):\n",
    "            sorted_dict[k] = v\n",
    "        \n",
    "        return sorted_dict\n",
    "    \n",
    "    def __get_score(self, y, y_predict):\n",
    "        if self.eval_kind == 'accuracy':\n",
    "            return accuracy_score(y, y_predict)\n",
    "        if self.eval_kind == 'precision':\n",
    "            return precision_score(y, y_predict)\n",
    "        if self.eval_kind == 'recall':\n",
    "            return recall_score(y, y_predict)\n",
    "        if self.eval_kind == 'f1':\n",
    "            return f1_score(y, y_predict)\n",
    "\n",
    "    def __preprocess_test(self, X_test):\n",
    "        # データ前処理\n",
    "        X_test_pre = self.__preprocess_X(X_test)\n",
    "\n",
    "        # 訓練データのヘッダから空データフレーム作成\n",
    "        df_cols_m = pd.DataFrame(None,\n",
    "                         columns=self.X_columns,\n",
    "                         dtype=float)\n",
    "#         # デバッグ文\n",
    "#         print('---df_cols_m start--------------------')\n",
    "#         display(df_cols_m)\n",
    "#         print('---df_cols_m end----------------------')\n",
    "        \n",
    "        # テストデータの列を訓練データに合わせる\n",
    "        X_test_concat = pd.concat([df_cols_m, X_test_pre])\n",
    "\n",
    "#         # デバッグ文\n",
    "#         display(X_test_concat)\n",
    "        \n",
    "        # 訓練データにない列を削除\n",
    "        X_test_drop = X_test_concat.drop(list(set(X_test_concat.columns.values)-set(self.X_columns)),axis=1)\n",
    "        \n",
    "\n",
    "        # テストデータに登場しなかったデータ項目をゼロ埋め\n",
    "        X_test_drop.loc[:,list(set(self.X_columns)-set(X_test_pre.columns.values))] = \\\n",
    "            X_test_drop.loc[:,list(set(self.X_columns)-set(X_test_pre.columns.values))].fillna(0, axis=1)\n",
    "\n",
    "#         # デバッグ文\n",
    "#         print('---X_test_drop start--------------------')\n",
    "#         display(X_test_drop)\n",
    "#         print('---X_test_drop end----------------------')\n",
    "\n",
    "        # 訓練データと合わせて並び替え\n",
    "        X_test_drop_reindex = X_test_drop.reindex(self.X_columns, axis=1)\n",
    "\n",
    "        # デバッグ文\n",
    "        print('---X_test_drop_reindex start--------------------')\n",
    "        display(X_test_drop_reindex)\n",
    "        print('---X_test_drop_reindex end----------------------')\n",
    "\n",
    "        return X_test_drop_reindex\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # データ前処理\n",
    "        X_test_pre_complete = self.__preprocess_test(X_test)\n",
    "        \n",
    "        return self.best_model.predict(X_test_pre_complete)\n",
    "                \n",
    "    def predict_proba(self, X_test):\n",
    "        # データ前処理\n",
    "        X_test_pre_complete = self.__preprocess_test(X_test)\n",
    "\n",
    "        return self.best_model.predict_proba(X_test_pre_complete)\n",
    "\n",
    "    def predict_proba_with_id(self, id, X_test):\n",
    "        proba = self.predict_proba(X_test)\n",
    "        \n",
    "        # 2列目が'1'の予測確率\n",
    "        proba_1 = proba[:, 1]\n",
    "        \n",
    "        # IDと予測確率の結合\n",
    "        ID_array = ID_test.values\n",
    "        ID_array_1dim = ID_array[:,0]\n",
    "        result = np.vstack((ID_array_1dim, proba_1))\n",
    "        result_df = pd.DataFrame(result).T\n",
    "        \n",
    "        # ヘッダをつける\n",
    "        result_df.columns = [self.ID_name, self.y_name]\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    # file_nameにAutoMLごとベストモデルを保存する\n",
    "    def save(self, file_name):\n",
    "        with open(file_name, mode='wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    # file_nameから学習済みモデルを保持したAutoMLを呼び出す\n",
    "    def load(self, file_name):\n",
    "        with open(file_name, mode='rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('../bank_marketing_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最終的なペルソナに従い、特徴量を抽出する\n",
    "- age:60以上\n",
    "- job:retired\n",
    "- marital：結婚経験あり\n",
    "- default(クレジットの支払い遅延)：なし\n",
    "- education(最終学歴)：basic.4y\n",
    "- contact(連絡デバイス)：cellular\n",
    "- pdays（前回の接触からの経過日数）：少ない\n",
    "- poutcome（以前のキャンペーン結果）：あり（初めての客でない）\n",
    "\n",
    "### ペルソナに用いた説明変数以外で重要なものも含める\n",
    "- emp.var.rate\n",
    "- cons.price.idx\n",
    "- cons.conf.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract = df_input.loc[:, ['age','job','marital','default','education','contact','pdays','poutcome',\n",
    "                            'emp.var.rate','cons.price.idx','cons.conf.idx','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>telephone</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>high.school</td>\n",
       "      <td>telephone</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital  default    education    contact  pdays  \\\n",
       "0   56  housemaid  married       no     basic.4y  telephone    999   \n",
       "1   57   services  married  unknown  high.school  telephone    999   \n",
       "\n",
       "      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx   y  \n",
       "0  nonexistent           1.1          93.994          -36.4  no  \n",
       "1  nonexistent           1.1          93.994          -36.4  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extract.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量と目的変数に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_extract.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>telephone</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>high.school</td>\n",
       "      <td>telephone</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital  default    education    contact  pdays  \\\n",
       "0   56  housemaid  married       no     basic.4y  telephone    999   \n",
       "1   57   services  married  unknown  high.school  telephone    999   \n",
       "\n",
       "      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  \n",
       "0  nonexistent           1.1          93.994          -36.4  \n",
       "1  nonexistent           1.1          93.994          -36.4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_extract['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    no\n",
       "1    no\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数のyes/noを1/0に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_val = df_y.apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_val.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummyエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカル変数\n",
    "categorical_columns = ['job','marital','default','education','contact','poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_dm = pd.get_dummies(data=df_X, dummy_na=True, drop_first=True, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'pdays', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'job_nan', 'marital_married', 'marital_single', 'marital_unknown',\n",
       "       'marital_nan', 'default_unknown', 'default_yes', 'default_nan',\n",
       "       'education_basic.6y', 'education_basic.9y', 'education_high.school',\n",
       "       'education_illiterate', 'education_professional.course',\n",
       "       'education_university.degree', 'education_unknown', 'education_nan',\n",
       "       'contact_telephone', 'contact_nan', 'poutcome_nonexistent',\n",
       "       'poutcome_success', 'poutcome_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_dm.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習モデルに入力するためNumpy配列に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_y_val)\n",
    "X = np.array(df_X_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 1 1 0]\n",
      "[[  56.   999.     1.1 ...,    1.     0.     0. ]\n",
      " [  57.   999.     1.1 ...,    1.     0.     0. ]\n",
      " [  56.   999.     1.1 ...,    1.     0.     0. ]\n",
      " ..., \n",
      " [  73.   999.    -1.1 ...,    1.     0.     0. ]\n",
      " [  44.   999.    -1.1 ...,    1.     0.     0. ]\n",
      " [  74.   999.    -1.1 ...,    0.     0.     0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HoldOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_X_dm, df_y_val, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic = Pipeline([('scl',StandardScaler()), ('est',LogisticRegression(random_state=1, class_weight=\"balanced\"))])\n",
    "random_forest = Pipeline([('scl',StandardScaler()), ('est',RandomForestClassifier(random_state=1, class_weight=\"balanced\"))])\n",
    "xgb = Pipeline([('scl',StandardScaler()), ('est',XGBClassifier(random_state=1, class_weight=\"balanced\"))])\n",
    "lgbm = Pipeline([('scl',StandardScaler()), ('est',LGBMClassifier(random_state=1, class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riode\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\riode\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('est', LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "        colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "        max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "        min_sp...ambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0))])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba = logistic.predict_proba(X_test)\n",
    "# y_pred_proba = random_forest.predict_proba(X_test)\n",
    "# y_pred_proba = xgb.predict_proba(X_test)\n",
    "y_pred_proba = lgbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベストな閾値を求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROIの計算処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roi(y_list: np.ndarray, attack_list: np.ndarray) -> int:\n",
    "    roi = 0\n",
    "    for (yes, attack) in zip(y_list, attack_list):\n",
    "    #     print(yes, attack)\n",
    "        if attack == 1:\n",
    "            roi += 5000*yes - 500*attack\n",
    "\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 閾値を変えてROIを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.0 , roi: 308000\n",
      "threshold: 0.01 , roi: 308000\n",
      "threshold: 0.02 , roi: 308000\n",
      "threshold: 0.03 , roi: 308000\n",
      "threshold: 0.04 , roi: 310000\n",
      "threshold: 0.05 , roi: 313000\n",
      "threshold: 0.06 , roi: 322500\n",
      "threshold: 0.07 , roi: 327000\n",
      "threshold: 0.08 , roi: 340500\n",
      "threshold: 0.09 , roi: 347000\n",
      "threshold: 0.1 , roi: 352500\n",
      "threshold: 0.11 , roi: 368000\n",
      "threshold: 0.12 , roi: 381500\n",
      "threshold: 0.13 , roi: 416000\n",
      "threshold: 0.14 , roi: 439000\n",
      "threshold: 0.15 , roi: 503000\n",
      "threshold: 0.16 , roi: 581000\n",
      "threshold: 0.17 , roi: 667500\n",
      "threshold: 0.18 , roi: 774000\n",
      "threshold: 0.19 , roi: 847500\n",
      "threshold: 0.2 , roi: 907000\n",
      "threshold: 0.21 , roi: 1033500\n",
      "threshold: 0.22 , roi: 1149000\n",
      "threshold: 0.23 , roi: 1254000\n",
      "threshold: 0.24 , roi: 1353500\n",
      "threshold: 0.25 , roi: 1415000\n",
      "threshold: 0.26 , roi: 1490500\n",
      "threshold: 0.27 , roi: 1566500\n",
      "threshold: 0.28 , roi: 1614000\n",
      "threshold: 0.29 , roi: 1699000\n",
      "threshold: 0.3 , roi: 1755000\n",
      "threshold: 0.31 , roi: 1800000\n",
      "threshold: 0.32 , roi: 1911000\n",
      "threshold: 0.33 , roi: 2035000\n",
      "threshold: 0.34 , roi: 2104000\n",
      "threshold: 0.35 , roi: 2124000\n",
      "threshold: 0.36 , roi: 2190000\n",
      "threshold: 0.37 , roi: 2214500\n",
      "threshold: 0.38 , roi: 2266000\n",
      "threshold: 0.39 , roi: 2291000\n",
      "threshold: 0.4 , roi: 2321500\n",
      "threshold: 0.41 , roi: 2333500\n",
      "threshold: 0.42 , roi: 2361000\n",
      "threshold: 0.43 , roi: 2363500\n",
      "threshold: 0.44 , roi: 2372500\n",
      "threshold: 0.45 , roi: 2367500\n",
      "threshold: 0.46 , roi: 2363000\n",
      "threshold: 0.47 , roi: 2381000\n",
      "threshold: 0.48 , roi: 2396500\n",
      "threshold: 0.49 , roi: 2411000\n",
      "threshold: 0.5 , roi: 2421500\n",
      "threshold: 0.51 , roi: 2445000\n",
      "threshold: 0.52 , roi: 2432500\n",
      "threshold: 0.53 , roi: 2439500\n",
      "threshold: 0.54 , roi: 2471500\n",
      "threshold: 0.55 , roi: 2467500\n",
      "threshold: 0.56 , roi: 2434500\n",
      "threshold: 0.57 , roi: 2427000\n",
      "threshold: 0.58 , roi: 2421000\n",
      "threshold: 0.59 , roi: 2406500\n",
      "threshold: 0.6 , roi: 2393500\n",
      "threshold: 0.61 , roi: 2370500\n",
      "threshold: 0.62 , roi: 2354500\n",
      "threshold: 0.63 , roi: 2353500\n",
      "threshold: 0.64 , roi: 2335000\n",
      "threshold: 0.65 , roi: 2320500\n",
      "threshold: 0.66 , roi: 2323000\n",
      "threshold: 0.67 , roi: 2289000\n",
      "threshold: 0.68 , roi: 2281500\n",
      "threshold: 0.69 , roi: 2271000\n",
      "threshold: 0.7 , roi: 2243000\n",
      "threshold: 0.71 , roi: 2234500\n",
      "threshold: 0.72 , roi: 2218000\n",
      "threshold: 0.73 , roi: 2172000\n",
      "threshold: 0.74 , roi: 2164000\n",
      "threshold: 0.75 , roi: 2115500\n",
      "threshold: 0.76 , roi: 2096000\n",
      "threshold: 0.77 , roi: 2039500\n",
      "threshold: 0.78 , roi: 1969500\n",
      "threshold: 0.79 , roi: 1900000\n",
      "threshold: 0.8 , roi: 1749000\n",
      "threshold: 0.81 , roi: 1620500\n",
      "threshold: 0.82 , roi: 1563000\n",
      "threshold: 0.83 , roi: 1475500\n",
      "threshold: 0.84 , roi: 1342000\n",
      "threshold: 0.85 , roi: 1214500\n",
      "threshold: 0.86 , roi: 1088500\n",
      "threshold: 0.87 , roi: 1019500\n",
      "threshold: 0.88 , roi: 941500\n",
      "threshold: 0.89 , roi: 834500\n",
      "threshold: 0.9 , roi: 745000\n",
      "threshold: 0.91 , roi: 712500\n",
      "threshold: 0.92 , roi: 671500\n",
      "threshold: 0.93 , roi: 635500\n",
      "threshold: 0.94 , roi: 527000\n",
      "threshold: 0.95 , roi: 410000\n",
      "threshold: 0.96 , roi: 221000\n",
      "threshold: 0.97 , roi: 47500\n",
      "threshold: 0.98 , roi: 0\n",
      "threshold: 0.99 , roi: 0\n",
      "threshold: 1.0 , roi: 0\n"
     ]
    }
   ],
   "source": [
    "best_roi = 0\n",
    "best_threshold = 0\n",
    "best_attack_list = np.ndarray([])\n",
    "\n",
    "for threshold in np.arange(0, 1.01, 0.01):\n",
    "    attack_list = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "    roi = calc_roi(y_test, attack_list)\n",
    "    print('threshold:', threshold, ', roi:', roi)\n",
    "    if roi > best_roi:\n",
    "        best_roi = roi\n",
    "        best_threshold = threshold\n",
    "        best_attack_list = attack_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471500\n",
      "0.54\n",
      "[0 0 1 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(best_roi)\n",
    "print(best_threshold)\n",
    "print(best_attack_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベストな閾値は上の通り"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アタックリストの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attack_list(dataset: pd.DataFrame, model: Pipeline, threshold: float) -> np.ndarray:\n",
    "\n",
    "    # ペルソナに用いた説明変数、重要な説明変数を含める(yは含めないように注意)\n",
    "    df_X = dataset.loc[:, ['age','job','marital','default','education','contact','pdays','poutcome',\n",
    "                            'emp.var.rate','cons.price.idx','cons.conf.idx']]\n",
    "    \n",
    "    # Dummyエンコーディング\n",
    "    categorical_columns = ['job','marital','default','education','contact','poutcome']\n",
    "    df_X_dm = pd.get_dummies(data=df_X, dummy_na=True, drop_first=True, columns=categorical_columns)\n",
    "    \n",
    "    # 機械学習モデルに入力するためNumpy配列に変換\n",
    "    X = np.array(df_X_dm)\n",
    "    \n",
    "    # Modelの生成\n",
    "    y_pred_proba = logistic.predict_proba(X)\n",
    "    \n",
    "    # アタックリストの作成\n",
    "    attack_list = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "    \n",
    "    return attack_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当日はテストデータを読み込む\n",
    "df_test = pd.read_csv('../bank_marketing_train.csv')\n",
    "final_attack_list = make_attack_list(df_test, logistic, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_attack_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アタックリストをcsv出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('attack.csv', final_attack_list,delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 期待される収益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yのリストを求める\n",
    "y = df_test['y']\n",
    "y_val = y.apply(lambda x: 1 if x == 'yes' else 0)\n",
    "y_list = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8169000"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROIの計算\n",
    "calc_roi(y_list=y_list, attack_list=final_attack_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （おまけ）yをすべて当てた時の理想収益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17082000"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[y_val == 1].size * (5000-500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelの予測精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  : 0.800349691797\n",
      "recall    : 0.639357218124\n",
      "precision : 0.311353431687\n",
      "f1        : 0.418773186093\n"
     ]
    }
   ],
   "source": [
    "print('accuracy  :', accuracy_score(y_true=y_list, y_pred=final_attack_list))\n",
    "print('recall    :', recall_score(y_true=y_list, y_pred=final_attack_list))\n",
    "print('precision :', precision_score(y_true=y_list, y_pred=final_attack_list))\n",
    "print('f1        :', f1_score(y_true=y_list, y_pred=final_attack_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33744"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
